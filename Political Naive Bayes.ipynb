{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes on Political Text\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details. You can download the required DB from the shared dropbox or from blackboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "import string\n",
    "from collections import Counter, defaultdict\n",
    "import os\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Feel free to include your text patterns functions\n",
    "#from text_functions_solutions import clean_tokenize, get_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tarad\\OneDrive\\Documents\\USD_GRAD_SCHOOL-C\\ADS509_AppliedTextMining\\Module_4\\Assignment_4\\TextClassification_assignment4\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Verifying database file\n",
    "# Change to target directory\n",
    "os.chdir('C:/Users/tarad/OneDrive/Documents/USD_GRAD_SCHOOL-C/ADS509_AppliedTextMining/Module_4/Assignment_4/TextClassification_assignment4')\n",
    "\n",
    "# Verify change and current directory\n",
    "print(os.getcwd())  \n",
    "# Check to see if file exists in current directory\n",
    "print(os.path.isfile(\"2020_Conventions.db\"))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5664768\n"
     ]
    }
   ],
   "source": [
    " # Prints the file size in bytes\n",
    "print(os.path.getsize(\"2020_Conventions.db\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_db = sqlite3.connect(\"2020_Conventions.db\")\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" exercise. First, we'll pull in the text \n",
    "for each party and prepare it for use in Naive Bayes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('conventions',)]\n"
     ]
    }
   ],
   "source": [
    "# Print out tables\n",
    "tables = convention_cur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\").fetchall()\n",
    "print(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Skip to content The Company Careers Press Freelancers Blog × Services Transcription Captions Foreign Subtitles Translation Freelancers About Contact Login « Return to Transcript Library home  Transcript Categories  All Transcripts 2020 Election Transcripts Classic Speech Transcripts Congressional Testimony & Hearing Transcripts Debate Transcripts Donald Trump Transcripts Entertainment Transcripts Financial Transcripts Interview Transcripts Political Transcripts Press Conference Transcripts Speech Transcripts Sports Transcripts Technology Transcripts Aug 21, 2020 2020 Democratic National Convention (DNC) Night 4 Transcript Rev  ›  Blog  ›  Transcripts  › 2020 Election Transcripts  ›  2020 Democratic National Convention (DNC) Night 4 Transcript Night 4 of the 2020 Democratic National Convention (DNC) on August 20. Read the full transcript of the event here. Transcribe Your Own Content  Try Rev for free  and save time transcribing, captioning, and subtitling.', 'Democratic'], ['I’m here by calling the full session of the 48th Quadrennial National Convention of the Democratic Party to order. Welcome all to our final session of this historic and memorable convention. We’ve called the 48th Quadrennial Democratic National Convention to order.', 'Democratic'], ['Every four years, we come together to reaffirm our democracy. This year, we’ve come to save it.', 'Democratic'], ['We fight for a more perfect union because we are fighting for the soul of this country and for our lives. And right now that fight is real.', 'Democratic'], ['We must come together to defeat Donald Trump, and elect Joe Biden and Kamala Harris as our next President and Vice President.', 'Democratic']]\n"
     ]
    }
   ],
   "source": [
    "convention_data = []\n",
    "\n",
    "# fill the above list up with items that are themselves lists. The \n",
    "# sublists will have two elements. The first element in the sublist\n",
    "# should be the speech in a single string. The second element\n",
    "# of the sublist should be the party. \n",
    "\n",
    "query_results = convention_cur.execute(\n",
    "                            '''\n",
    "                            SELECT text, party\n",
    "                            FROM conventions\n",
    "                            WHERE party IN ('Republican',  'Democratic')\n",
    "                            ''')\n",
    "\n",
    "for row in query_results :\n",
    "    # store the results in convention_data\n",
    "    convention_data.append([row[0], row[1]])  \n",
    "\n",
    "# Check a few rows to verify\n",
    "print(convention_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's a best practice to close up your DB connection when you're done\n",
    "convention_db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['When required by law.', 'Republican'],\n",
       " ['Joe, he believes we stand with our allies and stand up to our adversaries. Right now, we have a president who turns our tragedies into political weapons. Joe will be a president who turns our challenges into purpose. Joe will bring us together to build an economy that doesn’t leave anyone behind, where a good paying job is the floor, not the ceiling.',\n",
       "  'Democratic'],\n",
       " ['Under civilian direction.', 'Republican'],\n",
       " ['This time next year, I hope that we will have a government that is accountable to us. That guarantees health care as a human right.',\n",
       "  'Democratic'],\n",
       " ['Good evening, America. I’m Kimberly Guilfoyle. I speak to you tonight as a mother, a former prosecutor, a Latina, and a proud American and yes, a proud supporter of President Donald J. Trump. Why? Because he is the president who delivers for America. He built the greatest economy the world has ever known for the strivers, the working class and middle class. As commander in chief, he always puts America first. President Trump is the law and order president. Now, presidential leadership is not guaranteed. It is a choice. Biden, Harris and the rest of the socialists will fundamentally change this nation. They want open borders, closed schools, dangerous amnesty, and will selfishly send your jobs back to China while they get rich. They will defund, dismantle and destroy America’s law enforcement. When you are in trouble and need police, don’t count on the Democrats.',\n",
       "  'Republican']]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It'll be useful for us to have a large sample size than 2024 affords, since those speeches tend to be long and contiguous. Let's make a new list-of-lists called `conv_sent_data`. Instead of each first entry in the sublists being an entire speech, make each first entry just a sentence from the speech. Feel free to use NLTK's `sent_tokenize` [function](https://www.nltk.org/api/nltk.tokenize.sent_tokenize.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_sent_data = []\n",
    "\n",
    "# For each speech and party in convention_data, split the speech into sentences\n",
    "for speech, party in convention_data :\n",
    "    sentences = nltk.tokenize.sent_tokenize(speech) # Tokenize speech to sentences \n",
    "    for sentence in sentences:\n",
    "        conv_sent_data.append((sentence, party)) # Add each sentence with party label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's look at some random entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Dr.', 'Democratic'),\n",
       " ('Everybody gets a lawyer come on over to our country.', 'Republican'),\n",
       " ('Let us also take a moment to show our profound appreciation for a man who has always fought by our side, and stood up for our values.',\n",
       "  'Republican'),\n",
       " ('He put opportunity zones and the Trump tax bill that would drive investment and to our communities for decades to come.',\n",
       "  'Republican'),\n",
       " ('He just wasn’t there.', 'Republican')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(conv_sent_data,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time for our final cleaning before modeling. Go through `conv_sent_data` and take the following steps: \n",
    "\n",
    "1. Tokenize on whitespace\n",
    "1. Remove punctuation\n",
    "1. Remove tokens that fail the `isalpha` test\n",
    "1. Remove stopwords\n",
    "1. Casefold to lowercase\n",
    "1. Join the remaining tokens into a string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('need vote fight president sake', 'Republican'),\n",
       " ('military spouses decided start named rosie riveter campaign used recruit women workers world war',\n",
       "  'Republican'),\n",
       " ('without bravery heroism men women law enforcement saved', 'Republican'),\n",
       " ('president army special operators conducted raid', 'Republican'),\n",
       " ('joe biden may claim ally comes biden wants keep us completely',\n",
       "  'Republican')]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "# Add any additional stopwords\n",
    "custom_stop_words = set(['and', 'or', 'but', 'like', 'know']) \n",
    "stop_words = stop_words.union(custom_stop_words)\n",
    "\n",
    "punctuation = set(punctuation)\n",
    "\n",
    "clean_conv_sent_data = [] # list of tuples (sentence, party), with sentence cleaned\n",
    "\n",
    "for idx, (sentence, party) in enumerate(conv_sent_data) :\n",
    "    # Tokenize by splitting on whitespace\n",
    "    words = sentence.split()\n",
    "\n",
    "    # Remove punctuation, non-alphabetic tokens, and stop words, then lowercase the words\n",
    "    cleaned_words = [word.lower() for word in words if word.isalpha() and word.lower() not in stop_words and word.lower() not in punctuation]\n",
    "    \n",
    "    # Join cleaned words back into a cleaned sentence\n",
    "    cleaned_sentence = ' '.join(cleaned_words)\n",
    "\n",
    "    # Append cleaned sentence and party to clean_conv_sent_data list\n",
    "    clean_conv_sent_data.append((cleaned_sentence, party))\n",
    "\n",
    "# Check for some random cleaned sentences\n",
    "random.choices(clean_conv_sent_data,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, let's make our function to turn these into features. First we need to build our list of candidate words. I started my exploration at a cutoff of 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 1774 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in clean_conv_sent_data for w in t.split()]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text,fw) :\n",
    "    \"\"\"Given some text, this returns a dictionary holding the\n",
    "       feature words.\n",
    "       \n",
    "       Args: \n",
    "            * text: a piece of text in a continuous string. Assumes\n",
    "            text has been cleaned and case folded.\n",
    "            * fw: the *feature words* that we're considering. A word \n",
    "            in `text` must be in fw in order to be returned. This \n",
    "            prevents us from considering very rarely occurring words.\n",
    "        \n",
    "       Returns: \n",
    "            A dictionary with the words in `text` that appear in `fw`. \n",
    "            Words are only counted once. \n",
    "            If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
    "            then this would return a dictionary of \n",
    "            {'quick' : True,\n",
    "             'fox' :    True}\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    ret_dict = dict()\n",
    "\n",
    "    # Tokenize the text (split on spaces)\n",
    "    words = text.split()\n",
    "\n",
    "    # For each word in the text add it to the dictionary\n",
    "    for word in words:\n",
    "        if word in fw:\n",
    "            ret_dict[word] = True  # Indicating that the word appears in the text\n",
    "    \n",
    "    return ret_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(feature_words)>0)\n",
    "assert(conv_features(\"obama was the president\",feature_words)==\n",
    "       {'obama':True,'president':True})\n",
    "assert(conv_features(\"some people in america are citizens\",feature_words)==\n",
    "                     {'people':True,'america':True,\"citizens\":True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'obama': True, 'president': True}\n",
      "{'people': True, 'america': True, 'citizens': True}\n"
     ]
    }
   ],
   "source": [
    "# Testing functions by printing \n",
    "print(conv_features(\"obama was the president\", feature_words))  # Should print {'obama': True, 'president': True}\n",
    "print(conv_features(\"some people in america are citizens\", feature_words))  # Should print {'people': True, 'america': True, 'citizens': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.498\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             enforcement = True           Republ : Democr =     27.5 : 1.0\n",
      "                   votes = True           Democr : Republ =     21.6 : 1.0\n",
      "                 climate = True           Democr : Republ =     17.3 : 1.0\n",
      "                 destroy = True           Republ : Democr =     17.1 : 1.0\n",
      "                supports = True           Republ : Democr =     16.1 : 1.0\n",
      "                   media = True           Republ : Democr =     15.9 : 1.0\n",
      "                preserve = True           Republ : Democr =     15.1 : 1.0\n",
      "                  signed = True           Republ : Democr =     15.1 : 1.0\n",
      "              appreciate = True           Republ : Democr =     14.0 : 1.0\n",
      "                freedoms = True           Republ : Democr =     14.0 : 1.0\n",
      "                 private = True           Republ : Democr =     11.9 : 1.0\n",
      "                  defund = True           Republ : Democr =     10.9 : 1.0\n",
      "                    drug = True           Republ : Democr =     10.3 : 1.0\n",
      "                 special = True           Republ : Democr =     10.3 : 1.0\n",
      "                   trade = True           Republ : Democr =     10.0 : 1.0\n",
      "                everyday = True           Republ : Democr =      9.9 : 1.0\n",
      "                   local = True           Republ : Democr =      9.9 : 1.0\n",
      "                 allowed = True           Republ : Democr =      9.7 : 1.0\n",
      "                   elect = True           Democr : Republ =      9.6 : 1.0\n",
      "                   moved = True           Republ : Democr =      9.0 : 1.0\n",
      "                   bless = True           Republ : Democr =      9.0 : 1.0\n",
      "                    land = True           Republ : Democr =      8.9 : 1.0\n",
      "                  agenda = True           Republ : Democr =      8.8 : 1.0\n",
      "               countries = True           Republ : Democr =      8.8 : 1.0\n",
      "                   crime = True           Republ : Democr =      8.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
    "\n",
    "### My Observations\n",
    "\n",
    "In the Naive Bayes classifier results many of the most important words reflect clear differences between the two parties. For example, words like \"enforcment\", \"supports\", and \"defund\" are strongly linked to the Republican party, while words like \"votes\", \"climate\", and \"elect\" are often more used in Democratic speeches. This suggests that the two parties emphasize distinct topics. Republicans focusing on law enforcement and defunding issues, while Democrates tend to discuss voting and climate change. Alot of the more neutral terms like\"crime\" and \"freedoms\" are stil more notably more commmon inn Republican speeches. The models accuracy is 49.8%, meaning that there might be a big overlap in language use between both the parties, which would make it harder for the classifier to distinguish between the two parties in certain cases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\n",
    "        '''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "results = list(results) # Just to store it, since the query is time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[b'Here is my statement: https://t.co/djUy4lDpRR', 'Democratic'], [b'My latest for @FCNP: Action After Parkland #NeverAgain #AssaultWeaponsBan #GVRO https://t.co/FphN5Vq5nr', 'Democratic'], [b'#TalkFamDetention A3 I have more pictures along w/ reflections from my trip up here https://t.co/jWRZlo2WMY', 'Democratic'], [b\"What an honor to meet @YKleinHalevi, the keynote speaker at last night's #JCRCevent. Thank you Yossi and @JCRCMINNDAK for all you do to foster peace at home and abroad. https://t.co/WqYYNvdxbl\", 'Republican'], [b\"I sent the following letter with fellow Members of Congress to President-Elect Trump to reconsider Mr. Bannon's appointment to the WH. https://t.co/kKZAotEmSf\", 'Democratic']]\n"
     ]
    }
   ],
   "source": [
    "tweet_data = []\n",
    "\n",
    "# Now fill up tweet_data with sublists like we did on the convention speeches.\n",
    "# Note that this may take a bit of time, since we have a lot of tweets.\n",
    "# Fill up tweet_data with sublists where the tweet text is paired with the political party\n",
    "for row in results:\n",
    "    tweet_data.append([row[2], row[1]])  # row[2] is tweet_text, row[1] is party\n",
    "\n",
    "# Close the DB connection\n",
    "cong_db.close()\n",
    "\n",
    "# Check a few random entries\n",
    "print(random.choices(tweet_data, k=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20201014)\n",
    "\n",
    "tweet_data_sample = random.choices(tweet_data,k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: b'Earlier today, I spoke on the House Floor abt protecting health care for women and praised @PPmarmonte for their work on the Central Coast. https://t.co/WqgTRzT7VV'\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b'Go Tribe! #RallyTogether https://t.co/0NXutFL9L5'\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b\"Apparently, Trump thinks it's just too easy for students overwhelmed by the crushing burden of debt to pay off student loans #TrumpBudget https://t.co/ckYQO5T0Qh\"\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b'We\\xe2\\x80\\x99re grateful for our first responders, our rescue personnel, our firefighters, our police, and volunteers who have been working tirelessly to keep people safe, provide much-needed help, while putting their own lives on the line.\\n\\nhttps://t.co/eZPv0vMIz3'\n",
      "Actual party is Republican and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b'Let\\xe2\\x80\\x99s make it even Greater !! #KAG \\xf0\\x9f\\x87\\xba\\xf0\\x9f\\x87\\xb8 https://t.co/y9qoZD5L2z'\n",
      "Actual party is Republican and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b\"We have about 1hr until the @cavs tie up the series 2-2. I'm #ALLin216 @RepBarbaraLee you scared? #roadtovictory\"\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b'Congrats to @belliottsd on his new gig at SD City Hall. We are glad you will continue to serve\\xe2\\x80\\xa6 https://t.co/fkvMw3cqdI'\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b'We are really close, we have over $3500 raised toward the match right now. Whoot!! (That\\xe2\\x80\\x99s $7000 for the non-math majors in the room \\xf0\\x9f\\x98\\x82). Help us get there https://t.co/Tu34C472sD https://t.co/QsdQkYpsmC'\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b'Today, the comment period for @POTUS\\xe2\\x80\\x99s plan to expand offshore drilling opened to the public. You have 60 days (until March 9) to share why you oppose the proposed program directly with the Trump Administration. Comments can be made by email or mail. https://t.co/BaaYMeJxQn'\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b'Celebrated @ICSEastLA\\xe2\\x80\\x99s 22 years of Eastside commitment &amp; saluted community leaders at last night\\xe2\\x80\\x99s awards dinner! https://t.co/7V7gH8giVB'\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tweet, party in tweet_data_sample :\n",
    "\n",
    "    # Preprocess the tweet: use the conv_features function to extract features\n",
    "    features = conv_features(tweet, feature_words)\n",
    "\n",
    "    # Use the classifier to estimate the party based on the features\n",
    "    estimated_party = classifier.classify(features)  \n",
    "\n",
    "    \n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifer says {estimated_party}.\")\n",
    "    print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of counts by actual party and estimated party. \n",
    "# first key is actual, second is estimated\n",
    "parties = ['Republican','Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties :\n",
    "    for p1 in parties :\n",
    "        results[p][p1] = 0\n",
    "\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "for idx, tp in enumerate(tweet_data) :\n",
    "    tweet, party = tp    \n",
    "    # Now do the same thing as above, but we store the results rather\n",
    "    # than printing them. \n",
    "    # Preprocess the tweet \n",
    "    tweet = tweet.decode('utf-8') if isinstance(tweet, bytes) else tweet\n",
    "    features = conv_features(tweet, feature_words)  # Extract features\n",
    "   \n",
    "    # get the estimated party\n",
    "    estimated_party = classifier.classify(features) \n",
    "    \n",
    "    results[party][estimated_party] += 1\n",
    "    \n",
    "    if idx > num_to_score : \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'Republican': defaultdict(int,\n",
       "                         {'Republican': 2985, 'Democratic': 1387}),\n",
       "             'Democratic': defaultdict(int,\n",
       "                         {'Republican': 3965, 'Democratic': 1665})})"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "In the results,the classifier is struggling with distinguishing between Republican and Democratic tweets. For Republican tweets, the classifier correctly classified 2985 as Republican but misclassified 1387 as Democratic, For Democratic tweets, the classifier misclassified a large portion as Republican (3965) and only correctly classified 1665 as Democratic. This indicates that the might show some biased towards classifying tweets as Republican. This could because of overlapping vocabulary between the two parties or just insufficient distringuishing features in the tweets. The classifier's overall performance suggests a need for better feature engineering or rebalancing of training data to improve classification accuracy. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
